datafusion
==========

.. py:module:: datafusion

.. autoapi-nested-parse::

   DataFusion python package.

   This is a Python library that binds to Apache Arrow in-memory query engine DataFusion.
   See https://datafusion.apache.org/python for more information.



Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/datafusion/catalog/index
   /autoapi/datafusion/context/index
   /autoapi/datafusion/dataframe/index
   /autoapi/datafusion/expr/index
   /autoapi/datafusion/functions/index
   /autoapi/datafusion/input/index
   /autoapi/datafusion/object_store/index
   /autoapi/datafusion/plan/index
   /autoapi/datafusion/record_batch/index
   /autoapi/datafusion/substrait/index
   /autoapi/datafusion/udf/index


Attributes
----------

.. autoapisummary::

   datafusion.DFSchema


Classes
-------

.. autoapisummary::

   datafusion.Accumulator
   datafusion.AggregateUDF
   datafusion.Catalog
   datafusion.Database
   datafusion.ExecutionPlan
   datafusion.Expr
   datafusion.LogicalPlan
   datafusion.RecordBatch
   datafusion.RecordBatchStream
   datafusion.RuntimeConfig
   datafusion.SQLOptions
   datafusion.ScalarUDF
   datafusion.SessionConfig
   datafusion.Table
   datafusion.WindowFrame
   datafusion.WindowUDF


Functions
---------

.. autoapisummary::

   datafusion.col
   datafusion.column
   datafusion.lit
   datafusion.literal


Package Contents
----------------

.. py:class:: Accumulator

   Defines how an :py:class:`AggregateUDF` accumulates values.


   .. py:method:: evaluate() -> pyarrow.Scalar
      :abstractmethod:


      Return the resultant value.



   .. py:method:: merge(states: List[pyarrow.Array]) -> None
      :abstractmethod:


      Merge a set of states.



   .. py:method:: state() -> List[pyarrow.Scalar]
      :abstractmethod:


      Return the current state.



   .. py:method:: update(*values: pyarrow.Array) -> None
      :abstractmethod:


      Evaluate an array of values and update state.



.. py:class:: AggregateUDF(name: Optional[str], accumulator: Callable[[], Accumulator], input_types: list[pyarrow.DataType], return_type: pyarrow.DataType, state_type: list[pyarrow.DataType], volatility: Volatility | str)

   Class for performing scalar user-defined functions (UDF).

   Aggregate UDFs operate on a group of rows and return a single value. See
   also :py:class:`ScalarUDF` for operating on a row by row basis.

   Instantiate a user-defined aggregate function (UDAF).

   See :py:func:`udaf` for a convenience function and argument
   descriptions.


   .. py:method:: __call__(*args: datafusion.expr.Expr) -> datafusion.expr.Expr

      Execute the UDAF.

      This function is not typically called by an end user. These calls will
      occur during the evaluation of the dataframe.



   .. py:method:: udaf(accum: Callable[[], Accumulator], input_types: pyarrow.DataType | list[pyarrow.DataType], return_type: pyarrow.DataType, state_type: list[pyarrow.DataType], volatility: Volatility | str, name: Optional[str] = None) -> AggregateUDF
      :staticmethod:


      Create a new User-Defined Aggregate Function.

      If your :py:class:`Accumulator` can be instantiated with no arguments, you
      can simply pass it's type as ``accum``. If you need to pass additional arguments
      to it's constructor, you can define a lambda or a factory method. During runtime
      the :py:class:`Accumulator` will be constructed for every instance in
      which this UDAF is used. The following examples are all valid.

      .. code-block:: python
          import pyarrow as pa
          import pyarrow.compute as pc

          class Summarize(Accumulator):
              def __init__(self, bias: float = 0.0):
                  self._sum = pa.scalar(bias)

              def state(self) -> List[pa.Scalar]:
                  return [self._sum]

              def update(self, values: pa.Array) -> None:
                  self._sum = pa.scalar(self._sum.as_py() + pc.sum(values).as_py())

              def merge(self, states: List[pa.Array]) -> None:
                  self._sum = pa.scalar(self._sum.as_py() + pc.sum(states[0]).as_py())

              def evaluate(self) -> pa.Scalar:
                  return self._sum

          def sum_bias_10() -> Summarize:
              return Summarize(10.0)

          udaf1 = udaf(Summarize, pa.float64(), pa.float64(), [pa.float64()], "immutable")
          udaf2 = udaf(sum_bias_10, pa.float64(), pa.float64(), [pa.float64()], "immutable")
          udaf3 = udaf(lambda: Summarize(20.0), pa.float64(), pa.float64(), [pa.float64()], "immutable")

      :param accum: The accumulator python function.
      :param input_types: The data types of the arguments to ``accum``.
      :param return_type: The data type of the return value.
      :param state_type: The data types of the intermediate accumulation.
      :param volatility: See :py:class:`Volatility` for allowed values.
      :param name: A descriptive name for the function.

      :returns: A user-defined aggregate function, which can be used in either data
                aggregation or window function calls.



   .. py:attribute:: _udaf


.. py:class:: Catalog(catalog: datafusion._internal.Catalog)

   DataFusion data catalog.

   This constructor is not typically called by the end user.


   .. py:method:: database(name: str = 'public') -> Database

      Returns the database with the given ``name`` from this catalog.



   .. py:method:: names() -> list[str]

      Returns the list of databases in this catalog.



   .. py:attribute:: catalog


.. py:class:: Database(db: datafusion._internal.Database)

   DataFusion Database.

   This constructor is not typically called by the end user.


   .. py:method:: names() -> set[str]

      Returns the list of all tables in this database.



   .. py:method:: table(name: str) -> Table

      Return the table with the given ``name`` from this database.



   .. py:attribute:: db


.. py:class:: ExecutionPlan(plan: datafusion._internal.ExecutionPlan)

   Represent nodes in the DataFusion Physical Plan.

   This constructor should not be called by the end user.


   .. py:method:: __repr__() -> str

      Print a string representation of the physical plan.



   .. py:method:: children() -> List[ExecutionPlan]

      Get a list of children `ExecutionPlan`s that act as inputs to this plan.

      The returned list will be empty for leaf nodes such as scans, will contain a
      single value for unary nodes, or two values for binary nodes (such as joins).



   .. py:method:: display() -> str

      Print the physical plan.



   .. py:method:: display_indent() -> str

      Print an indented form of the physical plan.



   .. py:method:: from_proto(ctx: datafusion.context.SessionContext, data: bytes) -> ExecutionPlan
      :staticmethod:


      Create an ExecutionPlan from protobuf bytes.

      Tables created in memory from record batches are currently not supported.



   .. py:method:: to_proto() -> bytes

      Convert an ExecutionPlan into protobuf bytes.

      Tables created in memory from record batches are currently not supported.



   .. py:attribute:: _raw_plan


   .. py:property:: partition_count
      :type: int


      Returns the number of partitions in the physical plan.


.. py:class:: Expr(expr: datafusion._internal.expr.Expr)

   Expression object.

   Expressions are one of the core concepts in DataFusion. See
   :ref:`Expressions` in the online documentation for more information.

   This constructor should not be called by the end user.


   .. py:method:: __add__(rhs: Any) -> Expr

      Addition operator.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __and__(rhs: Expr) -> Expr

      Logical AND.



   .. py:method:: __eq__(rhs: Any) -> Expr

      Equal to.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __ge__(rhs: Any) -> Expr

      Greater than or equal to.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __getitem__(key: str | int) -> Expr

      Retrieve sub-object.

      If ``key`` is a string, returns the subfield of the struct.
      If ``key`` is an integer, retrieves the element in the array. Note that the
      element index begins at ``0``, unlike `array_element` which begins at ``1``.



   .. py:method:: __gt__(rhs: Any) -> Expr

      Greater than.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __invert__() -> Expr

      Binary not (~).



   .. py:method:: __le__(rhs: Any) -> Expr

      Less than or equal to.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __lt__(rhs: Any) -> Expr

      Less than.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __mod__(rhs: Any) -> Expr

      Modulo operator (%).

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __mul__(rhs: Any) -> Expr

      Multiplication operator.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __ne__(rhs: Any) -> Expr

      Not equal to.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __or__(rhs: Expr) -> Expr

      Logical OR.



   .. py:method:: __repr__() -> str

      Generate a string representation of this expression.



   .. py:method:: __richcmp__(other: Expr, op: int) -> Expr

      Comparison operator.



   .. py:method:: __sub__(rhs: Any) -> Expr

      Subtraction operator.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: __truediv__(rhs: Any) -> Expr

      Division operator.

      Accepts either an expression or any valid PyArrow scalar literal value.



   .. py:method:: alias(name: str) -> Expr

      Assign a name to the expression.



   .. py:method:: between(low: Any, high: Any, negated: bool = False) -> Expr

      Returns ``True`` if this expression is between a given range.

      :param low: lower bound of the range (inclusive).
      :param high: higher bound of the range (inclusive).
      :param negated: negates whether the expression is between a given range



   .. py:method:: canonical_name() -> str

      Returns a complete string representation of this expression.



   .. py:method:: cast(to: pyarrow.DataType[Any] | Type[float] | Type[int] | Type[str] | Type[bool]) -> Expr

      Cast to a new data type.



   .. py:method:: column(value: str) -> Expr
      :staticmethod:


      Creates a new expression representing a column.



   .. py:method:: column_name(plan: datafusion.plan.LogicalPlan) -> str

      Compute the output column name based on the provided logical plan.



   .. py:method:: display_name() -> str

      Returns the name of this expression as it should appear in a schema.

      This name will not include any CAST expressions.



   .. py:method:: distinct() -> ExprFuncBuilder

      Only evaluate distinct values for an aggregate function.

      This function will create an :py:class:`ExprFuncBuilder` that can be used to
      set parameters for either window or aggregate functions. If used on any other
      type of expression, an error will be generated when ``build()`` is called.



   .. py:method:: fill_nan(value: Any | Expr | None = None) -> Expr

      Fill NaN values with a provided value.



   .. py:method:: fill_null(value: Any | Expr | None = None) -> Expr

      Fill NULL values with a provided value.



   .. py:method:: filter(filter: Expr) -> ExprFuncBuilder

      Filter an aggregate function.

      This function will create an :py:class:`ExprFuncBuilder` that can be used to
      set parameters for either window or aggregate functions. If used on any other
      type of expression, an error will be generated when ``build()`` is called.



   .. py:method:: is_not_null() -> Expr

      Returns ``True`` if this expression is not null.



   .. py:method:: is_null() -> Expr

      Returns ``True`` if this expression is null.



   .. py:method:: literal(value: Any) -> Expr
      :staticmethod:


      Creates a new expression representing a scalar value.

      ``value`` must be a valid PyArrow scalar value or easily castable to one.



   .. py:method:: null_treatment(null_treatment: datafusion.common.NullTreatment) -> ExprFuncBuilder

      Set the treatment for ``null`` values for a window or aggregate function.

      This function will create an :py:class:`ExprFuncBuilder` that can be used to
      set parameters for either window or aggregate functions. If used on any other
      type of expression, an error will be generated when ``build()`` is called.



   .. py:method:: order_by(*exprs: Expr | SortExpr) -> ExprFuncBuilder

      Set the ordering for a window or aggregate function.

      This function will create an :py:class:`ExprFuncBuilder` that can be used to
      set parameters for either window or aggregate functions. If used on any other
      type of expression, an error will be generated when ``build()`` is called.



   .. py:method:: over(window: Window) -> Expr

      Turn an aggregate function into a window function.

      This function turns any aggregate function into a window function. With the
      exception of ``partition_by``, how each of the parameters is used is determined
      by the underlying aggregate function.

      :param window: Window definition



   .. py:method:: partition_by(*partition_by: Expr) -> ExprFuncBuilder

      Set the partitioning for a window function.

      This function will create an :py:class:`ExprFuncBuilder` that can be used to
      set parameters for either window or aggregate functions. If used on any other
      type of expression, an error will be generated when ``build()`` is called.



   .. py:method:: python_value() -> Any

      Extracts the Expr value into a PyObject.

      This is only valid for literal expressions.

      :returns: Python object representing literal value of the expression.



   .. py:method:: rex_call_operands() -> list[Expr]

      Return the operands of the expression based on it's variant type.

      Row expressions, Rex(s), operate on the concept of operands. Different
      variants of Expressions, Expr(s), store those operands in different
      datastructures. This function examines the Expr variant and returns
      the operands to the calling logic.



   .. py:method:: rex_call_operator() -> str

      Extracts the operator associated with a row expression type call.



   .. py:method:: rex_type() -> datafusion.common.RexType

      Return the Rex Type of this expression.

      A Rex (Row Expression) specifies a single row of data.That specification
      could include user defined functions or types. RexType identifies the
      row as one of the possible valid ``RexType``.



   .. py:method:: schema_name() -> str

      Returns the name of this expression as it should appear in a schema.

      This name will not include any CAST expressions.



   .. py:method:: sort(ascending: bool = True, nulls_first: bool = True) -> SortExpr

      Creates a sort :py:class:`Expr` from an existing :py:class:`Expr`.

      :param ascending: If true, sort in ascending order.
      :param nulls_first: Return null values first.



   .. py:method:: to_variant() -> Any

      Convert this expression into a python object if possible.



   .. py:method:: types() -> datafusion.common.DataTypeMap

      Return the ``DataTypeMap``.

      :returns: DataTypeMap which represents the PythonType, Arrow DataType, and
                SqlType Enum which this expression represents.



   .. py:method:: variant_name() -> str

      Returns the name of the Expr variant.

      Ex: ``IsNotNull``, ``Literal``, ``BinaryExpr``, etc



   .. py:method:: window_frame(window_frame: WindowFrame) -> ExprFuncBuilder

      Set the frame fora  window function.

      This function will create an :py:class:`ExprFuncBuilder` that can be used to
      set parameters for either window or aggregate functions. If used on any other
      type of expression, an error will be generated when ``build()`` is called.



   .. py:attribute:: __radd__


   .. py:attribute:: __rand__


   .. py:attribute:: __rmod__


   .. py:attribute:: __rmul__


   .. py:attribute:: __ror__


   .. py:attribute:: __rsub__


   .. py:attribute:: __rtruediv__


   .. py:attribute:: _to_pyarrow_types


   .. py:attribute:: expr


.. py:class:: LogicalPlan(plan: datafusion._internal.LogicalPlan)

   Logical Plan.

   A `LogicalPlan` is a node in a tree of relational operators (such as
   Projection or Filter).

   Represents transforming an input relation (table) to an output relation
   (table) with a potentially different schema. Plans form a dataflow tree
   where data flows from leaves up to the root to produce the query result.

   `LogicalPlan`s can be created by the SQL query planner, the DataFrame API,
   or programmatically (for example custom query languages).

   This constructor should not be called by the end user.


   .. py:method:: __repr__() -> str

      Generate a printable representation of the plan.



   .. py:method:: display() -> str

      Print the logical plan.



   .. py:method:: display_graphviz() -> str

      Print the graph visualization of the logical plan.

      Returns a `format`able structure that produces lines meant for graphical display
      using the `DOT` language. This format can be visualized using software from
      [`graphviz`](https://graphviz.org/)



   .. py:method:: display_indent() -> str

      Print an indented form of the logical plan.



   .. py:method:: display_indent_schema() -> str

      Print an indented form of the schema for the logical plan.



   .. py:method:: from_proto(ctx: datafusion.context.SessionContext, data: bytes) -> LogicalPlan
      :staticmethod:


      Create a LogicalPlan from protobuf bytes.

      Tables created in memory from record batches are currently not supported.



   .. py:method:: inputs() -> List[LogicalPlan]

      Returns the list of inputs to the logical plan.



   .. py:method:: to_proto() -> bytes

      Convert a LogicalPlan to protobuf bytes.

      Tables created in memory from record batches are currently not supported.



   .. py:method:: to_variant() -> Any

      Convert the logical plan into its specific variant.



   .. py:attribute:: _raw_plan


.. py:class:: RecordBatch(record_batch: datafusion._internal.RecordBatch)

   This class is essentially a wrapper for :py:class:`pyarrow.RecordBatch`.

   This constructor is generally not called by the end user.

   See the :py:class:`RecordBatchStream` iterator for generating this class.


   .. py:method:: to_pyarrow() -> pyarrow.RecordBatch

      Convert to :py:class:`pyarrow.RecordBatch`.



   .. py:attribute:: record_batch


.. py:class:: RecordBatchStream(record_batch_stream: datafusion._internal.RecordBatchStream)

   This class represents a stream of record batches.

   These are typically the result of a
   :py:func:`~datafusion.dataframe.DataFrame.execute_stream` operation.

   This constructor is typically not called by the end user.


   .. py:method:: __iter__() -> typing_extensions.Self

      Iterator function.



   .. py:method:: __next__() -> RecordBatch

      Iterator function.



   .. py:method:: next() -> RecordBatch | None

      See :py:func:`__next__` for the iterator function.



   .. py:attribute:: rbs


.. py:class:: RuntimeConfig

   Runtime configuration options.

   Create a new :py:class:`RuntimeConfig` with default values.


   .. py:method:: with_disk_manager_disabled() -> RuntimeConfig

      Disable the disk manager, attempts to create temporary files will error.

      :returns: A new :py:class:`RuntimeConfig` object with the updated setting.



   .. py:method:: with_disk_manager_os() -> RuntimeConfig

      Use the operating system's temporary directory for disk manager.

      :returns: A new :py:class:`RuntimeConfig` object with the updated setting.



   .. py:method:: with_disk_manager_specified(*paths: str | pathlib.Path) -> RuntimeConfig

      Use the specified paths for the disk manager's temporary files.

      :param paths: Paths to use for the disk manager's temporary files.

      :returns: A new :py:class:`RuntimeConfig` object with the updated setting.



   .. py:method:: with_fair_spill_pool(size: int) -> RuntimeConfig

      Use a fair spill pool with the specified size.

      This pool works best when you know beforehand the query has multiple spillable
      operators that will likely all need to spill. Sometimes it will cause spills
      even when there was sufficient memory (reserved for other operators) to avoid
      doing so::

          ┌───────────────────────z──────────────────────z───────────────┐
          │                       z                      z               │
          │                       z                      z               │
          │       Spillable       z       Unspillable    z     Free      │
          │        Memory         z        Memory        z    Memory     │
          │                       z                      z               │
          │                       z                      z               │
          └───────────────────────z──────────────────────z───────────────┘

      :param size: Size of the memory pool in bytes.

      :returns: A new :py:class:`RuntimeConfig` object with the updated setting.

      Examples usage::

          config = RuntimeConfig().with_fair_spill_pool(1024)



   .. py:method:: with_greedy_memory_pool(size: int) -> RuntimeConfig

      Use a greedy memory pool with the specified size.

      This pool works well for queries that do not need to spill or have a single
      spillable operator. See :py:func:`with_fair_spill_pool` if there are
      multiple spillable operators that all will spill.

      :param size: Size of the memory pool in bytes.

      :returns: A new :py:class:`RuntimeConfig` object with the updated setting.

      Example usage::

          config = RuntimeConfig().with_greedy_memory_pool(1024)



   .. py:method:: with_temp_file_path(path: str | pathlib.Path) -> RuntimeConfig

      Use the specified path to create any needed temporary files.

      :param path: Path to use for temporary files.

      :returns: A new :py:class:`RuntimeConfig` object with the updated setting.

      Example usage::

          config = RuntimeConfig().with_temp_file_path("/tmp")



   .. py:method:: with_unbounded_memory_pool() -> RuntimeConfig

      Use an unbounded memory pool.

      :returns: A new :py:class:`RuntimeConfig` object with the updated setting.



   .. py:attribute:: config_internal


.. py:class:: SQLOptions

   Options to be used when performing SQL queries.

   Create a new :py:class:`SQLOptions` with default values.

   The default values are:
   - DDL commands are allowed
   - DML commands are allowed
   - Statements are allowed


   .. py:method:: with_allow_ddl(allow: bool = True) -> SQLOptions

      Should DDL (Data Definition Language) commands be run?

      Examples of DDL commands include ``CREATE TABLE`` and ``DROP TABLE``.

      :param allow: Allow DDL commands to be run.

      :returns: A new :py:class:`SQLOptions` object with the updated setting.

      Example usage::

          options = SQLOptions().with_allow_ddl(True)



   .. py:method:: with_allow_dml(allow: bool = True) -> SQLOptions

      Should DML (Data Manipulation Language) commands be run?

      Examples of DML commands include ``INSERT INTO`` and ``DELETE``.

      :param allow: Allow DML commands to be run.

      :returns: A new :py:class:`SQLOptions` object with the updated setting.

      Example usage::

          options = SQLOptions().with_allow_dml(True)



   .. py:method:: with_allow_statements(allow: bool = True) -> SQLOptions

      Should statements such as ``SET VARIABLE`` and ``BEGIN TRANSACTION`` be run?

      :param allow: Allow statements to be run.

      :returns: py:class:SQLOptions` object with the updated setting.
      :rtype: A new

      Example usage::

          options = SQLOptions().with_allow_statements(True)



   .. py:attribute:: options_internal


.. py:class:: ScalarUDF(name: Optional[str], func: Callable[Ellipsis, _R], input_types: pyarrow.DataType | list[pyarrow.DataType], return_type: _R, volatility: Volatility | str)

   Class for performing scalar user-defined functions (UDF).

   Scalar UDFs operate on a row by row basis. See also :py:class:`AggregateUDF` for
   operating on a group of rows.

   Instantiate a scalar user-defined function (UDF).

   See helper method :py:func:`udf` for argument details.


   .. py:method:: __call__(*args: datafusion.expr.Expr) -> datafusion.expr.Expr

      Execute the UDF.

      This function is not typically called by an end user. These calls will
      occur during the evaluation of the dataframe.



   .. py:method:: udf(func: Callable[Ellipsis, _R], input_types: list[pyarrow.DataType], return_type: _R, volatility: Volatility | str, name: Optional[str] = None) -> ScalarUDF
      :staticmethod:


      Create a new User-Defined Function.

      :param func: A callable python function.
      :param input_types: The data types of the arguments to ``func``. This list
                          must be of the same length as the number of arguments.
      :param return_type: The data type of the return value from the python
                          function.
      :param volatility: See ``Volatility`` for allowed values.
      :param name: A descriptive name for the function.

      :returns:

                A user-defined aggregate function, which can be used in either data
                    aggregation or window function calls.



   .. py:attribute:: _udf


.. py:class:: SessionConfig(config_options: dict[str, str] | None = None)

   Session configuration options.

   Create a new :py:class:`SessionConfig` with the given configuration options.

   :param config_options: Configuration options.


   .. py:method:: set(key: str, value: str) -> SessionConfig

      Set a configuration option.

      Args:
      key: Option key.
      value: Option value.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_batch_size(batch_size: int) -> SessionConfig

      Customize batch size.

      :param batch_size: Batch size.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_create_default_catalog_and_schema(enabled: bool = True) -> SessionConfig

      Control if the default catalog and schema will be automatically created.

      :param enabled: Whether the default catalog and schema will be
                      automatically created.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_default_catalog_and_schema(catalog: str, schema: str) -> SessionConfig

      Select a name for the default catalog and schema.

      :param catalog: Catalog name.
      :param schema: Schema name.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_information_schema(enabled: bool = True) -> SessionConfig

      Enable or disable the inclusion of ``information_schema`` virtual tables.

      :param enabled: Whether to include ``information_schema`` virtual tables.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_parquet_pruning(enabled: bool = True) -> SessionConfig

      Enable or disable the use of pruning predicate for parquet readers.

      Pruning predicates will enable the reader to skip row groups.

      :param enabled: Whether to use pruning predicate for parquet readers.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_repartition_aggregations(enabled: bool = True) -> SessionConfig

      Enable or disable the use of repartitioning for aggregations.

      Enabling this improves parallelism.

      :param enabled: Whether to use repartitioning for aggregations.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_repartition_file_min_size(size: int) -> SessionConfig

      Set minimum file range size for repartitioning scans.

      :param size: Minimum file range size.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_repartition_file_scans(enabled: bool = True) -> SessionConfig

      Enable or disable the use of repartitioning for file scans.

      :param enabled: Whether to use repartitioning for file scans.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_repartition_joins(enabled: bool = True) -> SessionConfig

      Enable or disable the use of repartitioning for joins to improve parallelism.

      :param enabled: Whether to use repartitioning for joins.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_repartition_sorts(enabled: bool = True) -> SessionConfig

      Enable or disable the use of repartitioning for window functions.

      This may improve parallelism.

      :param enabled: Whether to use repartitioning for window functions.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_repartition_windows(enabled: bool = True) -> SessionConfig

      Enable or disable the use of repartitioning for window functions.

      This may improve parallelism.

      :param enabled: Whether to use repartitioning for window functions.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:method:: with_target_partitions(target_partitions: int) -> SessionConfig

      Customize the number of target partitions for query execution.

      Increasing partitions can increase concurrency.

      :param target_partitions: Number of target partitions.

      :returns: A new :py:class:`SessionConfig` object with the updated setting.



   .. py:attribute:: config_internal


.. py:class:: Table(table: datafusion._internal.Table)

   DataFusion table.

   This constructor is not typically called by the end user.


   .. py:method:: schema() -> pyarrow.Schema

      Returns the schema associated with this table.



   .. py:property:: kind
      :type: str


      Returns the kind of table.


   .. py:attribute:: table


.. py:class:: WindowFrame(units: str, start_bound: Optional[Any], end_bound: Optional[Any])

   Defines a window frame for performing window operations.

   Construct a window frame using the given parameters.

   :param units: Should be one of ``rows``, ``range``, or ``groups``.
   :param start_bound: Sets the preceding bound. Must be >= 0. If none, this
                       will be set to unbounded. If unit type is ``groups``, this
                       parameter must be set.
   :param end_bound: Sets the following bound. Must be >= 0. If none, this
                     will be set to unbounded. If unit type is ``groups``, this
                     parameter must be set.


   .. py:method:: get_frame_units() -> str

      Returns the window frame units for the bounds.



   .. py:method:: get_lower_bound() -> WindowFrameBound

      Returns starting bound.



   .. py:method:: get_upper_bound()

      Returns end bound.



   .. py:attribute:: window_frame


.. py:class:: WindowUDF(name: Optional[str], func: Callable[[], WindowEvaluator], input_types: list[pyarrow.DataType], return_type: pyarrow.DataType, volatility: Volatility | str)

   Class for performing window user-defined functions (UDF).

   Window UDFs operate on a partition of rows. See
   also :py:class:`ScalarUDF` for operating on a row by row basis.

   Instantiate a user-defined window function (UDWF).

   See :py:func:`udwf` for a convenience function and argument
   descriptions.


   .. py:method:: __call__(*args: datafusion.expr.Expr) -> datafusion.expr.Expr

      Execute the UDWF.

      This function is not typically called by an end user. These calls will
      occur during the evaluation of the dataframe.



   .. py:method:: udwf(func: Callable[[], WindowEvaluator], input_types: pyarrow.DataType | list[pyarrow.DataType], return_type: pyarrow.DataType, volatility: Volatility | str, name: Optional[str] = None) -> WindowUDF
      :staticmethod:


      Create a new User-Defined Window Function.

      If your :py:class:`WindowEvaluator` can be instantiated with no arguments, you
      can simply pass it's type as ``func``. If you need to pass additional arguments
      to it's constructor, you can define a lambda or a factory method. During runtime
      the :py:class:`WindowEvaluator` will be constructed for every instance in
      which this UDWF is used. The following examples are all valid.

      .. code-block:: python

          import pyarrow as pa

          class BiasedNumbers(WindowEvaluator):
              def __init__(self, start: int = 0) -> None:
                  self.start = start

              def evaluate_all(self, values: list[pa.Array], num_rows: int) -> pa.Array:
                  return pa.array([self.start + i for i in range(num_rows)])

          def bias_10() -> BiasedNumbers:
              return BiasedNumbers(10)

          udwf1 = udwf(BiasedNumbers, pa.int64(), pa.int64(), "immutable")
          udwf2 = udwf(bias_10, pa.int64(), pa.int64(), "immutable")
          udwf3 = udwf(lambda: BiasedNumbers(20), pa.int64(), pa.int64(), "immutable")

      :param func: A callable to create the window function.
      :param input_types: The data types of the arguments to ``func``.
      :param return_type: The data type of the return value.
      :param volatility: See :py:class:`Volatility` for allowed values.
      :param arguments: A list of arguments to pass in to the __init__ method for accum.
      :param name: A descriptive name for the function.

      :returns: A user-defined window function.



   .. py:attribute:: _udwf


.. py:function:: col(value: str)

   Create a column expression.


.. py:function:: column(value: str)

   Create a column expression.


.. py:function:: lit(value)

   Create a literal expression.


.. py:function:: literal(value)

   Create a literal expression.


.. py:data:: DFSchema

