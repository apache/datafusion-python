datafusion.dataframe
====================

.. py:module:: datafusion.dataframe

.. autoapi-nested-parse::

   :py:class:`DataFrame` is one of the core concepts in DataFusion.

   See :ref:`user_guide_concepts` in the online documentation for more information.



Classes
-------

.. autoapisummary::

   datafusion.dataframe.DataFrame


Module Contents
---------------

.. py:class:: DataFrame(df: datafusion._internal.DataFrame)

   Two dimensional table representation of data.

   See :ref:`user_guide_concepts` in the online documentation for more information.

   This constructor is not to be used by the end user.

   See :py:class:`~datafusion.context.SessionContext` for methods to
   create a :py:class:`DataFrame`.


   .. py:method:: __arrow_c_stream__(requested_schema: pyarrow.Schema) -> Any

      Export an Arrow PyCapsule Stream.

      This will execute and collect the DataFrame. We will attempt to respect the
      requested schema, but only trivial transformations will be applied such as only
      returning the fields listed in the requested schema if their data types match
      those in the DataFrame.

      :param requested_schema: Attempt to provide the DataFrame using this schema.

      :returns: Arrow PyCapsule object.



   .. py:method:: __getitem__(key: str | List[str]) -> DataFrame

      Return a new :py:class`DataFrame` with the specified column or columns.

      :param key: Column name or list of column names to select.

      :returns: DataFrame with the specified column or columns.



   .. py:method:: __repr__() -> str

      Return a string representation of the DataFrame.

      :returns: String representation of the DataFrame.



   .. py:method:: aggregate(group_by: list[datafusion.expr.Expr], aggs: list[datafusion.expr.Expr]) -> DataFrame

      Aggregates the rows of the current DataFrame.

      :param group_by: List of expressions to group by.
      :param aggs: List of expressions to aggregate.

      :returns: DataFrame after aggregation.



   .. py:method:: cache() -> DataFrame

      Cache the DataFrame as a memory table.

      :returns: Cached DataFrame.



   .. py:method:: collect() -> list[pyarrow.RecordBatch]

      Execute this :py:class:`DataFrame` and collect results into memory.

      Prior to calling ``collect``, modifying a DataFrme simply updates a plan
      (no actual computation is performed). Calling ``collect`` triggers the
      computation.

      :returns: List of :py:class:`pyarrow.RecordBatch` collected from the DataFrame.



   .. py:method:: collect_partitioned() -> list[list[pyarrow.RecordBatch]]

      Execute this DataFrame and collect all partitioned results.

      This operation returns :py:class:`pyarrow.RecordBatch` maintaining the input
      partitioning.

      :returns:

                List of list of :py:class:`RecordBatch` collected from the
                    DataFrame.



   .. py:method:: count() -> int

      Return the total number of rows in this :py:class:`DataFrame`.

      Note that this method will actually run a plan to calculate the
      count, which may be slow for large or complicated DataFrames.

      :returns: Number of rows in the DataFrame.



   .. py:method:: describe() -> DataFrame

      Return the statistics for this DataFrame.

      Only summarized numeric datatypes at the moments and returns nulls
      for non-numeric datatypes.

      The output format is modeled after pandas.

      :returns: A summary DataFrame containing statistics.



   .. py:method:: distinct() -> DataFrame

      Return a new :py:class:`DataFrame` with all duplicated rows removed.

      :returns: DataFrame after removing duplicates.



   .. py:method:: except_all(other: DataFrame) -> DataFrame

      Calculate the exception of two :py:class:`DataFrame`.

      The two :py:class:`DataFrame` must have exactly the same schema.

      :param other: DataFrame to calculate exception with.

      :returns: DataFrame after exception.



   .. py:method:: execute_stream() -> datafusion.record_batch.RecordBatchStream

      Executes this DataFrame and returns a stream over a single partition.

      :returns: Record Batch Stream over a single partition.



   .. py:method:: execute_stream_partitioned() -> list[datafusion.record_batch.RecordBatchStream]

      Executes this DataFrame and returns a stream for each partition.

      :returns: One record batch stream per partition.



   .. py:method:: execution_plan() -> datafusion._internal.ExecutionPlan

      Return the execution/physical plan.

      :returns: Execution plan.



   .. py:method:: explain(verbose: bool = False, analyze: bool = False) -> DataFrame

      Return a DataFrame with the explanation of its plan so far.

      If ``analyze`` is specified, runs the plan and reports metrics.

      :param verbose: If ``True``, more details will be included.
      :param analyze: If ``Tru`e``, the plan will run and metrics reported.

      :returns: DataFrame with the explanation of its plan.



   .. py:method:: filter(*predicates: datafusion.expr.Expr) -> DataFrame

      Return a DataFrame for which ``predicate`` evaluates to ``True``.

      Rows for which ``predicate`` evaluates to ``False`` or ``None`` are filtered
      out.  If more than one predicate is provided, these predicates will be
      combined as a logical AND. If more complex logic is required, see the
      logical operations in :py:mod:`~datafusion.functions`.

      :param predicates: Predicate expression(s) to filter the DataFrame.

      :returns: DataFrame after filtering.



   .. py:method:: intersect(other: DataFrame) -> DataFrame

      Calculate the intersection of two :py:class:`DataFrame`.

      The two :py:class:`DataFrame` must have exactly the same schema.

      :param other: DataFrame to intersect with.

      :returns: DataFrame after intersection.



   .. py:method:: join(right: DataFrame, join_keys: tuple[list[str], list[str]], how: str) -> DataFrame

      Join this :py:class:`DataFrame` with another :py:class:`DataFrame`.

      Join keys are a pair of lists of column names in the left and right
      dataframes, respectively. These lists must have the same length.

      :param right: Other DataFrame to join with.
      :param join_keys: Tuple of two lists of column names to join on.
      :param how: Type of join to perform. Supported types are "inner", "left",
                  "right", "full", "semi", "anti".

      :returns: DataFrame after join.



   .. py:method:: limit(count: int, offset: int = 0) -> DataFrame

      Return a new :py:class:`DataFrame` with a limited number of rows.

      :param count: Number of rows to limit the DataFrame to.
      :param offset: Number of rows to skip.

      :returns: DataFrame after limiting.



   .. py:method:: logical_plan() -> datafusion._internal.LogicalPlan

      Return the unoptimized ``LogicalPlan``.

      :returns: Unoptimized logical plan.



   .. py:method:: optimized_logical_plan() -> datafusion._internal.LogicalPlan

      Return the optimized ``LogicalPlan``.

      :returns: Optimized logical plan.



   .. py:method:: repartition(num: int) -> DataFrame

      Repartition a DataFrame into ``num`` partitions.

      The batches allocation uses a round-robin algorithm.

      :param num: Number of partitions to repartition the DataFrame into.

      :returns: Repartitioned DataFrame.



   .. py:method:: repartition_by_hash(*exprs: datafusion.expr.Expr, num: int) -> DataFrame

      Repartition a DataFrame using a hash partitioning scheme.

      :param exprs: Expressions to evaluate and perform hashing on.
      :param num: Number of partitions to repartition the DataFrame into.

      :returns: Repartitioned DataFrame.



   .. py:method:: schema() -> pyarrow.Schema

      Return the :py:class:`pyarrow.Schema` of this DataFrame.

      The output schema contains information on the name, data type, and
      nullability for each column.

      :returns: Describing schema of the DataFrame



   .. py:method:: select(*exprs: datafusion.expr.Expr | str) -> DataFrame

      Project arbitrary expressions into a new :py:class:`DataFrame`.

      :param exprs: Either column names or :py:class:`~datafusion.expr.Expr` to select.

      :returns: DataFrame after projection. It has one column for each expression.

      Example usage:

      The following example will return 3 columns from the original dataframe.
      The first two columns will be the original column ``a`` and ``b`` since the
      string "a" is assumed to refer to column selection. Also a duplicate of
      column ``a`` will be returned with the column name ``alternate_a``::

          df = df.select("a", col("b"), col("a").alias("alternate_a"))




   .. py:method:: select_columns(*args: str) -> DataFrame

      Filter the DataFrame by columns.

      :returns: DataFrame only containing the specified columns.



   .. py:method:: show(num: int = 20) -> None

      Execute the DataFrame and print the result to the console.

      :param num: Number of lines to show.



   .. py:method:: sort(*exprs: datafusion.expr.Expr) -> DataFrame

      Sort the DataFrame by the specified sorting expressions.

      Note that any expression can be turned into a sort expression by
      calling its` ``sort`` method.

      :param exprs: Sort expressions, applied in order.

      :returns: DataFrame after sorting.



   .. py:method:: to_arrow_table() -> pyarrow.Table

      Execute the :py:class:`DataFrame` and convert it into an Arrow Table.

      :returns: Arrow Table.



   .. py:method:: to_pandas() -> pandas.DataFrame

      Execute the :py:class:`DataFrame` and convert it into a Pandas DataFrame.

      :returns: Pandas DataFrame.



   .. py:method:: to_polars() -> polars.DataFrame

      Execute the :py:class:`DataFrame` and convert it into a Polars DataFrame.

      :returns: Polars DataFrame.



   .. py:method:: to_pydict() -> dict[str, list[Any]]

      Execute the :py:class:`DataFrame` and convert it into a dictionary of lists.

      :returns: Dictionary of lists.



   .. py:method:: to_pylist() -> list[dict[str, Any]]

      Execute the :py:class:`DataFrame` and convert it into a list of dictionaries.

      :returns: List of dictionaries.



   .. py:method:: union(other: DataFrame, distinct: bool = False) -> DataFrame

      Calculate the union of two :py:class:`DataFrame`.

      The two :py:class:`DataFrame` must have exactly the same schema.

      :param other: DataFrame to union with.
      :param distinct: If ``True``, duplicate rows will be removed.

      :returns: DataFrame after union.



   .. py:method:: union_distinct(other: DataFrame) -> DataFrame

      Calculate the distinct union of two :py:class:`DataFrame`.

      The two :py:class:`DataFrame` must have exactly the same schema.
      Any duplicate rows are discarded.

      :param other: DataFrame to union with.

      :returns: DataFrame after union.



   .. py:method:: unnest_columns(*columns: str, preserve_nulls: bool = True) -> DataFrame

      Expand columns of arrays into a single row per array element.

      :param columns: Column names to perform unnest operation on.
      :param preserve_nulls: If False, rows with null entries will not be
                             returned.

      :returns: A DataFrame with the columns expanded.



   .. py:method:: with_column(name: str, expr: datafusion.expr.Expr) -> DataFrame

      Add an additional column to the DataFrame.

      :param name: Name of the column to add.
      :param expr: Expression to compute the column.

      :returns: DataFrame with the new column.



   .. py:method:: with_column_renamed(old_name: str, new_name: str) -> DataFrame

      Rename one column by applying a new projection.

      This is a no-op if the column to be renamed does not exist.

      The method supports case sensitive rename with wrapping column name
      into one the following symbols (" or ' or \`).

      :param old_name: Old column name.
      :param new_name: New column name.

      :returns: DataFrame with the column renamed.



   .. py:method:: write_csv(path: str | pathlib.Path, with_header: bool = False) -> None

      Execute the :py:class:`DataFrame`  and write the results to a CSV file.

      :param path: Path of the CSV file to write.
      :param with_header: If true, output the CSV header row.



   .. py:method:: write_json(path: str | pathlib.Path) -> None

      Execute the :py:class:`DataFrame` and write the results to a JSON file.

      :param path: Path of the JSON file to write.



   .. py:method:: write_parquet(path: str | pathlib.Path, compression: str = 'uncompressed', compression_level: int | None = None) -> None

      Execute the :py:class:`DataFrame` and write the results to a Parquet file.

      :param path: Path of the Parquet file to write.
      :param compression: Compression type to use.
      :param compression_level: Compression level to use.



   .. py:attribute:: df


